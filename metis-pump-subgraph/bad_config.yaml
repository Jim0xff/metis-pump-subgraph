model: llama2
train:
  epochs: 4
  batch_size: 2
  learning_rate: 2e-5